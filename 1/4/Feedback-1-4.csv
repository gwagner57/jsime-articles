"name","emailAddress","affiliation","feedback","ip","created_at"
"Sascha Holzhauer","Sascha.Holzhauer@uni-kassel.de","University of Kassel","Certainly, diversity is required to advance the field of modelling and simulation, to allow new perspectives and new ideas to evolve. However, often a lack of structure, scrutiny, and accuracy (in the application of models, rather than in the models themselves) can be observed because there is often no clear expectation, no clear definition of good science in modelling and simulation. Especially in social simulation, there seem to be too many niches to hide from being criticised, mainly because a common understanding about what is good science and the establishment of standards of practise are still missing. In that sense, there is a clear lack of unity to control diversity. There are exceptions for model description, but deficits in model building, validation, and publication.\r\nDiversity in terms of model frameworks (!) and tools, at least in agent-based modelling is prevalent, often exceeds what is necessary for good competition and hinders development as too much resources are bound in developing tools anew rather than consolidating and extending existing ones. Unfruitful conceptual/terminological diversity is just an outcome of this development. Collaboration among developers should be incentivised and improved to achieve a diverse, but consolidated and complementary zoo of model (frameworks) and tools. Certainly, as a pre-condition abstraction layers on a meso level are needed that support modelling systems across discipline borders and give orientation for common usage of model frameworks.","141.51.212.130","2018-07-17T08:55:59.497Z"
"Niniet Arvitrida","arvietrida@gmail.com","Institut Teknologi Sepuluh Nopember (ITS), Indonesia","\r\nThis panel discussion provides a comprehensive perspective to the simulation society on the complexity of the simulation user diversity. Although the various background of the simulation user can enrich the innovative use of a simulation approach, it may also lead to a communication challenge. With this case, I agree that one of the potential causes of this issue is due to the limited standard of the conceptual modeling process.\r\n\r\nTo my experience, the challenge of creating model abstraction rises when the agent-based modeling approach is introduced in some OR community, such as in Industrial Engineer (IE) society. I have tried to adopt ODD for abstracting some agent-based models, but IE people do not easy to make use ODD to describe (for example) how the emergence is generated, and how sensing and interaction are defined. UML is also difficult to apply, particularly for people or students who do not have a background in programming. \r\n\r\nDo you have any comment and suggestion about this?\r\n","36.73.232.158","2018-07-09T03:03:12.826Z"
"Edmund Chattoe-Brown","ecb18@le.ac.uk","School of Media, Communication and Sociology, University of Leicester","This debate seems to take place at a very high level of abstraction. It is an interesting question whether the reader would realise that “computer simulation” is meant to involve “doing science” of some kind.\r\n\r\nClearly the first challenge is that we aren’t all doing the same thing. If you want to develop a “tool” or “package” then your success criteria are things like “usability” and “expressiveness”. The research designs to justify a package would be something like observing users or re-implementing a sample of existing models and seeing how well that worked. (I recall the bad old days of social simulation when every clunky new package would show how it could implement the Lotka-Volterra model. This simply didn’t sort the sheep from the goats or rather the foxes from the rabbits.) Some of the relevant groups are interested in “instrumental” tasks: Can we locate machines on a shop floor to minimise “travel time” either better or in a feasible processing time for more machines? (It is an interesting question for Operational Research whether “purely instrumental” tasks are useful. It is one thing to optimise machine locations on the assumption that workers don’t dodge into the toilet for a sneaky read when they can get away with it but an empirical matter whether they do or not.) Research designs for this class involve actually increasing the productivity of a shop floor and it may not matter that the simulation does not reflect every detail of the social system. A third group (which I belong to) is interested in “descriptive” tasks: How can we justify the claim that a model “represents” social reality (in the broadest sense). This plainly has something to do with “data” in the form of calibration and validation. Research designs here must make claims based on the relationship between model and data. Clearly, there is unlikely to be agreement that we should only be doing one of these things (they are all valuable) but we not must muddle means and ends and particularly appropriate justifications for each approach (or worse still not justify what we are doing at all).\r\n\r\nThe second big issue is the nature of our assumptions and communities. An empirical justification for an element of a model (people have on average five close friends plus or minus 2) is relatively uncontroversial. But justifying assumptions on “technical” grounds (if we don’t do this then the model doesn’t converge or we can’t do the mathematics) is much more problematic and, because it cannot be resolved empirically, is always at risk of creating communities defined by their ability to suspend certain sorts of disbelief. If a simulation method requires (or even typically makes) certain assumptions about population homogeneity (for example) then it will never reconcile those to whom those assumptions don’t “appeal” let alone those who know them to be empirically wrong. This could be an argument for descriptive modelling and Agent-Based Modelling that both minimise “technical” assumptions and maximise the aspiration for “empirical support” but in any event we need to recognise the potential problems created by inward looking communities with non-empirical shared assumptions.\r\n\r\nThe final challenge is external to simulation and that is that you cannot “automate” good science. In my entirely subjective experience I have never yet read an “ODD” description that was easier or simpler than a properly constructed narrative about the model. Conversely, I have read a good number that made a very simple model acutely painful and added nothing. This isn’t an argument against standards but against substituting them for scientific effort and mental flexibility.\r\n\r\nMy conclusion is that we need to start by being clear about what we are “doing” and what counts as evidence that we “did it effectively”. Debates about what we “ought” to be doing are probably pointless. Once we know what we are doing, we need to think about ways to avoid separate communities simply converging on a set of shared non-empirical assumptions (Systems Dynamics reviewers for ABM papers and vice versa, going to each other’s conferences and all the other things that modern academia makes so difficult!) Finally, we need to move away from high-level debates about “principle” and towards much more detailed critique of actual research. What assumptions do System Dynamics models commonly make and how well are those assumptions supported, either intellectually or conceptually? What happens if those assumptions are relaxed (using different methods if need be?) We all know that some of this research goes on but far too little (and it is far too little known) in proportion to the importance of the challenge of getting the whole of “computer simulation” to fulfill its full potential in the physical and social sciences.\r\n","143.210.205.125","2018-07-04T10:40:05.713Z"
"Dallas Bell","DllsB7@aol.com","SystematicPoliticalScience","Do the panelists think unity and diversity should include categories for individual and nation-state behavioral motivations and contributions to computer simulation(s) based on eschatological beliefs, e.g. individual and nation-state utopian beliefs, goals, and thus behavior are very different from adherents of fatalist beliefs etc.?","172.164.91.102","2018-06-29T13:50:44.829Z"
"Jackie Kazil","jackiekazil@gmail.com","George Mason University","As a woman in STEM and a woman who works increasing diversity in science my first reaction to the title was to look at the author names. At which point I saw six male names. I showed this to a couple of other women in STEM and one gasped that an article on diversity, would be written by six men. You need to clarify what kind of diversity of computing simulation this is about otherwise large audiences will assume that is about gender and/or racial diversity. I would recommend to you this in the first couple of usages of 'diversity' in the text. \r\n","96.231.224.195","2018-06-27T13:15:47.432Z"